{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eae0cc21-0345-4717-a878-0219248debda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Any, Optional, Callable\n",
    "\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "import random\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, FloatType, DoubleType\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, OneHotEncoder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdd0e97-a021-4bae-a49e-5808059995b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/12 10:35:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    ".config(\"spark.driver.memory\", \"6g\")\\\n",
    ".appName(\"diabetes_indicators\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc891114-bce6-421d-afa2-5a1507cf27c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+-------+------+--------+--------+------+--------+-------+-------+--------+-------+-------+--------+--------+---+--------+-------+-----+-------+\n",
      "|DIABETE3|CHCKIDNY|_RFHYPE5|TOLDHI2| _BMI5|SMOKE100|CVDSTRK3|_MICHD|_TOTINDA|_FRTLT1|_VEGLT1|_RFDRHV5|MEDCOST|GENHLTH|PHYSHLTH|MENTHLTH|SEX|_AGEG5YR|_MRACE1|EDUCA|INCOME2|\n",
      "+--------+--------+--------+-------+------+--------+--------+------+--------+-------+-------+--------+-------+-------+--------+--------+---+--------+-------+-----+-------+\n",
      "|       0|       0|       1|      1|2522.0|       1|       0|     0|       1|      1|      1|       0|      0|    2.0|     2.0|    88.0|  0|    10.0|    1.0|  6.0|    8.0|\n",
      "|       0|       0|       0|      0|2407.0|       0|       0|     0|       0|      0|      1|       0|      0|    2.0|    88.0|    88.0|  0|     8.0|    1.0|  4.0|    3.0|\n",
      "|       2|       0|       0|      0|2468.0|       1|       0|     0|       1|      1|      1|       0|      0|    3.0|    88.0|    88.0|  0|    13.0|    1.0|  6.0|    8.0|\n",
      "|       2|       0|       0|      0|2317.0|       1|       0|     0|       1|      0|      0|       0|      0|    2.0|    88.0|    88.0|  0|     7.0|    1.0|  5.0|    6.0|\n",
      "|       0|       0|       0|      1|2800.0|       0|       0|     0|       0|      0|      0|       1|      0|    2.0|    88.0|    10.0|  0|     4.0|    1.0|  6.0|    8.0|\n",
      "+--------+--------+--------+-------+------+--------+--------+------+--------+-------+-------+--------+-------+-------+--------+--------+---+--------+-------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./data/diabetes/final_diabetes_dataset.csv\", header=True, inferSchema=True, sep=\",\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd3d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.limit(100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d54dad-6b81-451a-9d46-afd8235167ea",
   "metadata": {},
   "source": [
    "# Feature Scaling and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22c0161-9345-4167-b412-9315776704b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_data(df: pyspark.sql.DataFrame, map_dict: dict, colName: str) -> pyspark.sql.DataFrame:\n",
    "    \"\"\" Function to transform predictor variable based on map_dict \"\"\"\n",
    "    map_col = F.create_map([F.lit(x) for i in map_dict.items() for x in i])\n",
    "    new_df = df.withColumn(colName, map_col[F.col(colName)])\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582baa3e-eb30-4665-9fab-28389154d310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PHYSHLTH\", F.when(df[\"PHYSHLTH\"] == 88, 0).otherwise(df[\"PHYSHLTH\"]))\n",
    "df = df.withColumn(\"MENTHLTH\", F.when(df[\"MENTHLTH\"] == 88, 0).otherwise(df[\"MENTHLTH\"]))\n",
    "\n",
    "df = transform_data(df, {v:idx for idx, v in enumerate(range(1, 14))}, \"_AGEG5YR\")\n",
    "df = transform_data(df, {v:idx for idx, v in enumerate(range(1, 8))}, \"_MRACE1\")\n",
    "df = transform_data(df, {v:idx for idx, v in enumerate(range(1, 7))}, \"EDUCA\")\n",
    "df = transform_data(df, {v:idx for idx, v in enumerate(range(1, 9))}, \"INCOME2\")\n",
    "df = transform_data(df, {v:idx for idx, v in enumerate(range(1, 6))}, \"GENHLTH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a196ff8-2f46-46d1-9dcf-45d27e226c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_data(df: pyspark.sql.DataFrame, feats: List) -> pyspark.sql.DataFrame: \n",
    "    \"\"\" Function to scale the data \"\"\"\n",
    "    def scale_feat(df: pyspark.sql.DataFrame, feat: str) -> pyspark.sql.DataFrame:\n",
    "        \"\"\" Function to scale numeric columns of dataframe \"\"\"\n",
    "        unlist = F.udf(lambda x: round(float(list(x)[0]), 3), DoubleType())\n",
    "\n",
    "        assembler = VectorAssembler(inputCols=[feat], outputCol=feat+\"_vec\")\n",
    "        scaler = StandardScaler(inputCol=feat+\"_vec\", outputCol=feat+\"_scaled\")\n",
    "        pipeline = Pipeline(stages=[\n",
    "            assembler,\n",
    "            scaler\n",
    "        ])\n",
    "\n",
    "        if not os.path.exists(f\"./scalers/{feat}_pipeline\"):\n",
    "            pipeline_model = pipeline.fit(df)\n",
    "            pipeline_model.save(f\"./scalers/{feat}_pipeline\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Loading pipeline from : ./scalers/{feat}_pipeline\")\n",
    "            pipeline_model = PipelineModel.load(f\"./scalers/{feat}_pipeline\")\n",
    "\n",
    "        df = pipeline_model.transform(df).withColumn(feat+\"_scaled\", unlist(feat+\"_scaled\")).drop(feat+\"_vec\")\n",
    "\n",
    "        return df, feat+\"_scaled\"\n",
    "    \n",
    "    new_feats = list()\n",
    "    for feat in feats:\n",
    "        df, _name = scale_feat(df, feat)\n",
    "        new_feats.append(_name)\n",
    "        \n",
    "    return df, new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f65ff3-b0d2-4592-b01c-1c8ea26205b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./scalers/\"):\n",
    "    os.mkdir(\"./scalers\")\n",
    "\n",
    "\n",
    "num_cols = [\"_BMI5\", \"PHYSHLTH\", \"MENTHLTH\"]\n",
    "cat_cols = [x for x in df.columns if x not in [\"DIABETE3\"]+num_cols]\n",
    "\n",
    "df_train, df_test = df.randomSplit([.8, .2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b6c766-69be-4460-8a1c-06180f4873aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pipeline from : ./scalers/_BMI5_pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pipeline from : ./scalers/PHYSHLTH_pipeline\n",
      "Loading pipeline from : ./scalers/MENTHLTH_pipeline\n",
      "Loading pipeline from : ./scalers/_BMI5_pipeline\n",
      "Loading pipeline from : ./scalers/PHYSHLTH_pipeline\n",
      "Loading pipeline from : ./scalers/MENTHLTH_pipeline\n"
     ]
    }
   ],
   "source": [
    "df_train_scaled, train_new_feats = scale_data(df_train, num_cols)\n",
    "df_test_scaled, test_new_feats = scale_data(df_test, num_cols)\n",
    "\n",
    "df_train_scaled = df_train_scaled.withColumnRenamed(\"DIABETE3\", \"label\")\n",
    "df_test_scaled = df_test_scaled.withColumnRenamed(\"DIABETE3\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ce63e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled = df_train_scaled.repartition(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79346440-bd07-4fc6-afc1-50edb52120b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", seed=32)\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=32)\n",
    "log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", standardization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a8f8ba6-0dd7-4cd9-bb81-e149e4a38ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paramGrid_dtree = ParamGridBuilder() \\\n",
    ".addGrid(dtree.maxDepth, [5, 10, 15, 20])\\\n",
    ".build()\n",
    "\n",
    "paramGrid_rf = ParamGridBuilder()\\\n",
    ".addGrid(rf.maxDepth, [5, 10, 15, 20])\\\n",
    ".build()\n",
    "\n",
    "paramGrid_logreg = ParamGridBuilder()\\\n",
    ".addGrid(log_reg.maxIter, [20, 50, 100])\\\n",
    ".addGrid(log_reg.tol, [1e-2, 1e-4, 1e-6])\\\n",
    ".addGrid(log_reg.threshold, [.5, .7])\\\n",
    ".build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cba92253-d61b-4f3c-9e32-fd049c869d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_dtree = Pipeline(\n",
    "    stages=[\n",
    "        VectorAssembler(inputCols=cat_cols + train_new_feats, outputCol=\"features\"),\n",
    "        dtree\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_rf = Pipeline(\n",
    "    stages=[\n",
    "        VectorAssembler(inputCols=cat_cols + train_new_feats, outputCol=\"features\"),\n",
    "        rf\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_logreg = Pipeline(\n",
    "    stages=[\n",
    "        VectorAssembler(inputCols=cat_cols + train_new_feats, outputCol=\"features\"),\n",
    "        log_reg\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f00de6-e175-48c9-90f1-426487c059bb",
   "metadata": {},
   "source": [
    "# Model Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880c08f-8816-4cb1-a661-038c16427027",
   "metadata": {},
   "source": [
    "## - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c0c6c8-fed2-4878-9ffe-434c932962b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 10:36:53 WARN DAGScheduler: Broadcasting large task binary with size 1027.3 KiB\n",
      "23/10/12 10:37:03 WARN DAGScheduler: Broadcasting large task binary with size 1027.3 KiB\n",
      "23/10/12 10:37:04 WARN DAGScheduler: Broadcasting large task binary with size 1274.2 KiB\n",
      "23/10/12 10:37:06 WARN DAGScheduler: Broadcasting large task binary with size 1519.3 KiB\n",
      "23/10/12 10:37:08 WARN DAGScheduler: Broadcasting large task binary with size 1760.7 KiB\n",
      "23/10/12 10:37:12 WARN DAGScheduler: Broadcasting large task binary with size 1995.2 KiB\n",
      "23/10/12 10:37:17 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/12 10:37:22 WARN DAGScheduler: Broadcasting large task binary with size 1412.0 KiB\n",
      "23/10/12 10:38:41 WARN DAGScheduler: Broadcasting large task binary with size 1017.8 KiB\n",
      "23/10/12 10:39:09 WARN DAGScheduler: Broadcasting large task binary with size 1017.8 KiB\n",
      "23/10/12 10:39:12 WARN DAGScheduler: Broadcasting large task binary with size 1260.5 KiB\n",
      "23/10/12 10:39:15 WARN DAGScheduler: Broadcasting large task binary with size 1509.6 KiB\n",
      "23/10/12 10:39:18 WARN DAGScheduler: Broadcasting large task binary with size 1755.4 KiB\n",
      "23/10/12 10:39:22 WARN DAGScheduler: Broadcasting large task binary with size 1990.1 KiB\n",
      "23/10/12 10:39:27 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/12 10:39:32 WARN DAGScheduler: Broadcasting large task binary with size 1398.0 KiB\n",
      "23/10/12 10:40:20 WARN DAGScheduler: Broadcasting large task binary with size 1040.0 KiB\n",
      "23/10/12 10:40:29 WARN DAGScheduler: Broadcasting large task binary with size 1040.0 KiB\n",
      "23/10/12 10:40:30 WARN DAGScheduler: Broadcasting large task binary with size 1290.6 KiB\n",
      "23/10/12 10:40:31 WARN DAGScheduler: Broadcasting large task binary with size 1545.9 KiB\n",
      "23/10/12 10:40:32 WARN DAGScheduler: Broadcasting large task binary with size 1793.1 KiB\n",
      "23/10/12 10:40:33 WARN DAGScheduler: Broadcasting large task binary with size 2023.7 KiB\n",
      "23/10/12 10:40:34 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/12 10:40:36 WARN DAGScheduler: Broadcasting large task binary with size 1414.9 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "crossval_dtree = CrossValidator(estimator=pipeline_dtree, \n",
    "                               estimatorParamMaps=paramGrid_dtree, \n",
    "                               evaluator=MulticlassClassificationEvaluator(),\n",
    "                               numFolds=3)\n",
    "cvmodel_dtree = crossval_dtree.fit(df_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f23e4040-22f5-4c0b-8599-7dc4d03eac6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7912102002347752, 0.7933607056277938, 0.7797563972636286, 0.76369564240532]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmodel_dtree.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501de3bd-92f1-459e-b037-7ac483c2457c",
   "metadata": {},
   "source": [
    "## - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85de93b5-8d55-4324-b359-bc490c81c851",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 10:41:10 WARN DAGScheduler: Broadcasting large task binary with size 1488.2 KiB\n",
      "23/10/12 10:41:12 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/10/12 10:41:16 WARN DAGScheduler: Broadcasting large task binary with size 1573.8 KiB\n",
      "23/10/12 10:41:31 WARN DAGScheduler: Broadcasting large task binary with size 1488.2 KiB\n",
      "23/10/12 10:41:38 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/10/12 10:41:49 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "23/10/12 10:42:04 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "23/10/12 10:42:18 WARN DAGScheduler: Broadcasting large task binary with size 1016.4 KiB\n",
      "23/10/12 10:42:25 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "23/10/12 10:42:44 WARN DAGScheduler: Broadcasting large task binary with size 1237.0 KiB\n",
      "23/10/12 10:42:51 WARN DAGScheduler: Broadcasting large task binary with size 11.9 MiB\n",
      "23/10/12 10:43:13 WARN DAGScheduler: Broadcasting large task binary with size 1425.9 KiB\n",
      "23/10/12 10:43:22 WARN DAGScheduler: Broadcasting large task binary with size 15.4 MiB\n",
      "23/10/12 10:43:52 WARN DAGScheduler: Broadcasting large task binary with size 1542.0 KiB\n",
      "23/10/12 10:44:01 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "23/10/12 10:44:35 WARN DAGScheduler: Broadcasting large task binary with size 1488.2 KiB\n",
      "23/10/12 10:44:42 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/10/12 10:44:52 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "23/10/12 10:45:07 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "23/10/12 10:45:12 WARN DAGScheduler: Broadcasting large task binary with size 1016.4 KiB\n",
      "23/10/12 10:45:15 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "23/10/12 10:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1237.0 KiB\n",
      "23/10/12 10:45:23 WARN DAGScheduler: Broadcasting large task binary with size 11.9 MiB\n",
      "23/10/12 10:45:29 WARN DAGScheduler: Broadcasting large task binary with size 1425.9 KiB\n",
      "23/10/12 10:45:32 WARN DAGScheduler: Broadcasting large task binary with size 15.4 MiB\n",
      "23/10/12 10:45:41 WARN DAGScheduler: Broadcasting large task binary with size 1542.0 KiB\n",
      "23/10/12 10:45:45 WARN DAGScheduler: Broadcasting large task binary with size 19.2 MiB\n",
      "23/10/12 10:45:54 WARN DAGScheduler: Broadcasting large task binary with size 1587.5 KiB\n",
      "23/10/12 10:45:58 WARN DAGScheduler: Broadcasting large task binary with size 23.0 MiB\n",
      "23/10/12 10:46:08 WARN DAGScheduler: Broadcasting large task binary with size 1550.7 KiB\n",
      "23/10/12 10:46:12 WARN DAGScheduler: Broadcasting large task binary with size 26.6 MiB\n",
      "23/10/12 10:46:34 WARN DAGScheduler: Broadcasting large task binary with size 1461.7 KiB\n",
      "23/10/12 10:46:45 WARN DAGScheduler: Broadcasting large task binary with size 29.9 MiB\n",
      "23/10/12 10:47:29 WARN DAGScheduler: Broadcasting large task binary with size 1304.1 KiB\n",
      "23/10/12 10:47:39 WARN DAGScheduler: Broadcasting large task binary with size 32.8 MiB\n",
      "23/10/12 10:48:25 WARN DAGScheduler: Broadcasting large task binary with size 1122.1 KiB\n",
      "23/10/12 10:48:35 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "23/10/12 10:50:00 WARN DAGScheduler: Broadcasting large task binary with size 1471.2 KiB\n",
      "23/10/12 10:50:08 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/10/12 10:50:12 WARN DAGScheduler: Broadcasting large task binary with size 1555.0 KiB\n",
      "23/10/12 10:50:19 WARN DAGScheduler: Broadcasting large task binary with size 1471.2 KiB\n",
      "23/10/12 10:50:21 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/10/12 10:50:24 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "23/10/12 10:50:29 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "23/10/12 10:50:35 WARN DAGScheduler: Broadcasting large task binary with size 8.5 MiB\n",
      "23/10/12 10:50:40 WARN DAGScheduler: Broadcasting large task binary with size 1214.6 KiB\n",
      "23/10/12 10:50:42 WARN DAGScheduler: Broadcasting large task binary with size 11.6 MiB\n",
      "23/10/12 10:50:48 WARN DAGScheduler: Broadcasting large task binary with size 1403.9 KiB\n",
      "23/10/12 10:50:51 WARN DAGScheduler: Broadcasting large task binary with size 15.1 MiB\n",
      "23/10/12 10:51:00 WARN DAGScheduler: Broadcasting large task binary with size 1527.2 KiB\n",
      "23/10/12 10:51:03 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "23/10/12 10:51:13 WARN DAGScheduler: Broadcasting large task binary with size 1471.2 KiB\n",
      "23/10/12 10:51:15 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/10/12 10:51:19 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "23/10/12 10:51:29 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "23/10/12 10:51:47 WARN DAGScheduler: Broadcasting large task binary with size 8.5 MiB\n",
      "23/10/12 10:52:04 WARN DAGScheduler: Broadcasting large task binary with size 1214.6 KiB\n",
      "23/10/12 10:52:12 WARN DAGScheduler: Broadcasting large task binary with size 11.6 MiB\n",
      "23/10/12 10:52:33 WARN DAGScheduler: Broadcasting large task binary with size 1403.9 KiB\n",
      "23/10/12 10:52:42 WARN DAGScheduler: Broadcasting large task binary with size 15.1 MiB\n",
      "23/10/12 10:53:09 WARN DAGScheduler: Broadcasting large task binary with size 1527.2 KiB\n",
      "23/10/12 10:53:20 WARN DAGScheduler: Broadcasting large task binary with size 18.9 MiB\n",
      "23/10/12 10:53:51 WARN DAGScheduler: Broadcasting large task binary with size 1573.6 KiB\n",
      "23/10/12 10:54:01 WARN DAGScheduler: Broadcasting large task binary with size 22.6 MiB\n",
      "23/10/12 10:54:35 WARN DAGScheduler: Broadcasting large task binary with size 1537.6 KiB\n",
      "23/10/12 10:54:46 WARN DAGScheduler: Broadcasting large task binary with size 26.2 MiB\n",
      "23/10/12 10:55:14 WARN DAGScheduler: Broadcasting large task binary with size 1450.8 KiB\n",
      "23/10/12 10:55:18 WARN DAGScheduler: Broadcasting large task binary with size 29.5 MiB\n",
      "23/10/12 10:55:31 WARN DAGScheduler: Broadcasting large task binary with size 1288.8 KiB\n",
      "23/10/12 10:55:35 WARN DAGScheduler: Broadcasting large task binary with size 32.3 MiB\n",
      "23/10/12 10:55:49 WARN DAGScheduler: Broadcasting large task binary with size 1108.5 KiB\n",
      "23/10/12 10:55:53 WARN DAGScheduler: Broadcasting large task binary with size 17.7 MiB\n",
      "23/10/12 10:56:20 WARN DAGScheduler: Broadcasting large task binary with size 1497.7 KiB\n",
      "23/10/12 10:56:24 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/10/12 10:56:34 WARN DAGScheduler: Broadcasting large task binary with size 1587.1 KiB\n",
      "23/10/12 10:56:57 WARN DAGScheduler: Broadcasting large task binary with size 1497.7 KiB\n",
      "23/10/12 10:57:04 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/10/12 10:57:15 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "23/10/12 10:57:29 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "23/10/12 10:57:43 WARN DAGScheduler: Broadcasting large task binary with size 1026.5 KiB\n",
      "23/10/12 10:57:50 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "23/10/12 10:58:07 WARN DAGScheduler: Broadcasting large task binary with size 1262.5 KiB\n",
      "23/10/12 10:58:15 WARN DAGScheduler: Broadcasting large task binary with size 12.0 MiB\n",
      "23/10/12 10:58:36 WARN DAGScheduler: Broadcasting large task binary with size 1446.0 KiB\n",
      "23/10/12 10:58:45 WARN DAGScheduler: Broadcasting large task binary with size 15.6 MiB\n",
      "23/10/12 10:59:14 WARN DAGScheduler: Broadcasting large task binary with size 1584.9 KiB\n",
      "23/10/12 10:59:23 WARN DAGScheduler: Broadcasting large task binary with size 9.1 MiB\n",
      "23/10/12 10:59:58 WARN DAGScheduler: Broadcasting large task binary with size 1497.7 KiB\n",
      "23/10/12 11:00:05 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/10/12 11:00:11 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "23/10/12 11:00:16 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "23/10/12 11:00:19 WARN DAGScheduler: Broadcasting large task binary with size 1026.5 KiB\n",
      "23/10/12 11:00:22 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 11:00:27 WARN DAGScheduler: Broadcasting large task binary with size 1262.5 KiB\n",
      "23/10/12 11:00:29 WARN DAGScheduler: Broadcasting large task binary with size 12.0 MiB\n",
      "23/10/12 11:00:36 WARN DAGScheduler: Broadcasting large task binary with size 1446.0 KiB\n",
      "23/10/12 11:00:39 WARN DAGScheduler: Broadcasting large task binary with size 15.6 MiB\n",
      "23/10/12 11:00:47 WARN DAGScheduler: Broadcasting large task binary with size 1584.9 KiB\n",
      "23/10/12 11:00:51 WARN DAGScheduler: Broadcasting large task binary with size 19.5 MiB\n",
      "23/10/12 11:01:00 WARN DAGScheduler: Broadcasting large task binary with size 1616.1 KiB\n",
      "23/10/12 11:01:04 WARN DAGScheduler: Broadcasting large task binary with size 23.3 MiB\n",
      "23/10/12 11:01:15 WARN DAGScheduler: Broadcasting large task binary with size 1560.7 KiB\n",
      "23/10/12 11:01:20 WARN DAGScheduler: Broadcasting large task binary with size 26.9 MiB\n",
      "23/10/12 11:01:58 WARN DAGScheduler: Broadcasting large task binary with size 1435.9 KiB\n",
      "23/10/12 11:02:10 WARN DAGScheduler: Broadcasting large task binary with size 30.1 MiB\n",
      "23/10/12 11:02:56 WARN DAGScheduler: Broadcasting large task binary with size 1269.8 KiB\n",
      "23/10/12 11:03:06 WARN DAGScheduler: Broadcasting large task binary with size 32.9 MiB\n",
      "23/10/12 11:03:52 WARN DAGScheduler: Broadcasting large task binary with size 1084.0 KiB\n",
      "23/10/12 11:04:01 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "23/10/12 11:05:15 WARN DAGScheduler: Broadcasting large task binary with size 1542.0 KiB\n",
      "23/10/12 11:05:17 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/10/12 11:05:21 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "23/10/12 11:05:26 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n",
      "23/10/12 11:05:31 WARN DAGScheduler: Broadcasting large task binary with size 1197.7 KiB\n",
      "23/10/12 11:05:34 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n",
      "23/10/12 11:05:42 WARN DAGScheduler: Broadcasting large task binary with size 1541.2 KiB\n",
      "23/10/12 11:05:45 WARN DAGScheduler: Broadcasting large task binary with size 13.8 MiB\n",
      "23/10/12 11:05:54 WARN DAGScheduler: Broadcasting large task binary with size 1839.1 KiB\n",
      "23/10/12 11:05:58 WARN DAGScheduler: Broadcasting large task binary with size 18.5 MiB\n",
      "23/10/12 11:06:08 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/10/12 11:06:13 WARN DAGScheduler: Broadcasting large task binary with size 23.6 MiB\n",
      "23/10/12 11:06:38 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/12 11:06:52 WARN DAGScheduler: Broadcasting large task binary with size 29.1 MiB\n",
      "23/10/12 11:07:43 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/12 11:07:59 WARN DAGScheduler: Broadcasting large task binary with size 34.5 MiB\n",
      "23/10/12 11:08:53 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/12 11:09:10 WARN DAGScheduler: Broadcasting large task binary with size 39.7 MiB\n",
      "23/10/12 11:10:07 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/10/12 11:10:15 WARN DAGScheduler: Broadcasting large task binary with size 44.3 MiB\n",
      "23/10/12 11:10:33 WARN DAGScheduler: Broadcasting large task binary with size 1863.4 KiB\n",
      "[Stage 1929:>                                                       (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "crossval_rf = CrossValidator(estimator=pipeline_rf, \n",
    "                               estimatorParamMaps=paramGrid_rf, \n",
    "                               evaluator=MulticlassClassificationEvaluator(),\n",
    "                               numFolds=3)\n",
    "cvmodel_rf = crossval_rf.fit(df_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56fe9446-fa66-4cec-9d70-ed2ca193cd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7585544594555061,\n",
       " 0.7870592152906328,\n",
       " 0.7943679202221721,\n",
       " 0.7967513844578309]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmodel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17c235a4-1b48-4fc0-a3e3-26321ea00f58",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 11:20:28 WARN CacheManager: Asked to cache already cached data.\n",
      "23/10/12 11:20:28 WARN CacheManager: Asked to cache already cached data.\n",
      "23/10/12 11:20:30 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/10/12 11:20:30 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "[Stage 7374:>                                                       (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "crossval_log_reg = CrossValidator(estimator=pipeline_logreg, \n",
    "                               estimatorParamMaps=paramGrid_logreg, \n",
    "                               evaluator=MulticlassClassificationEvaluator(),\n",
    "                               numFolds=3)\n",
    "cvmodel_log_reg = crossval_log_reg.fit(df_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b720820-23d8-4911-abcc-072088660386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7943157207658739,\n",
       " 0.7943157207658739,\n",
       " 0.7936749154071325,\n",
       " 0.7936749154071325,\n",
       " 0.7936749154071325,\n",
       " 0.7936749154071325,\n",
       " 0.7943157207658739,\n",
       " 0.7943157207658739,\n",
       " 0.7936801529260931,\n",
       " 0.7936801529260931,\n",
       " 0.7936887999328142,\n",
       " 0.7936887999328142,\n",
       " 0.7943157207658739,\n",
       " 0.7943157207658739,\n",
       " 0.7936801529260931,\n",
       " 0.7936801529260931,\n",
       " 0.7936887999328142,\n",
       " 0.7936887999328142]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmodel_log_reg.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32491e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
