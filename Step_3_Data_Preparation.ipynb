{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302a0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import functools\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col, isnan, when\n",
    "from pyspark.sql.types import IntegerType, DoubleType, BooleanType\n",
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a203ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/11 22:31:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"diabetes_indicators\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58cff38",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3216a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in Male: 111706\n",
      "Number of records in Female: 141974\n"
     ]
    }
   ],
   "source": [
    "df_male = spark.read.csv(\"./data/diabetes/diabetes_male_data_with_missing.csv\", header=True, inferSchema=True)\n",
    "df_female = spark.read.csv(\"./data/diabetes/diabetes_female_data_with_missing.csv\", header=True, inferSchema=True)\n",
    "\n",
    "print(f\"Number of records in Male: {df_male.count()}\")\n",
    "print(f\"Number of records in Female: {df_female.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35119f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionAll(dfs: List):\n",
    "    \"\"\" Function to merge two sources of data \"\"\"\n",
    "    unioned_df = functools.reduce(lambda df1, df2: df1.union(df2.select(df1.columns)), dfs)\n",
    "    return unioned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e46624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = unionAll([df_male, df_female])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcef3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.columns == df_male.columns and df.columns == df_female.columns, \"There has been a join error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a55977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
